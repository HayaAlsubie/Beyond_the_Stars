{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c15f467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_csv(\"all_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad57c840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19345 entries, 0 to 19344\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Region             19345 non-null  object \n",
      " 1   City               19345 non-null  object \n",
      " 2   Place Type         19345 non-null  object \n",
      " 3   Place Category     19345 non-null  object \n",
      " 4   Place Name         19345 non-null  object \n",
      " 5   Rating             19345 non-null  float64\n",
      " 6   Review Text        19143 non-null  object \n",
      " 7   Reviewer Language  19345 non-null  object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "review.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6b3fc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Region', 'City', 'Place Type', 'Place Category', 'Place Name',\n",
       "       'Rating', 'Review Text', 'Reviewer Language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a63a2326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/farajay96/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/farajay96/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download stopwords if not done already\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5d3f0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19143, 8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1.1: Drop rows with missing Review Text\n",
    "review = review.dropna(subset=['Review Text'])\n",
    "\n",
    "review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "304b6cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17762, 8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1.2: Remove duplicate rows (based on Review Text + Place Name)\n",
    "review = review.drop_duplicates(subset=['Review Text', 'Place Name'])\n",
    "review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e4faaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17762, 8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1.1: Drop rows with missing Review Text\n",
    "review = review.dropna(subset=['Review Text'])\n",
    "review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d77cbb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17762, 8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1.2: Remove duplicate rows (based on Review Text + Place Name)\n",
    "review = review.drop_duplicates(subset=['Review Text', 'Place Name'])\n",
    "review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400984f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        location best good chains outlets available wi...\n",
       "1        rooms good enough accommodate family kids neat...\n",
       "2         reasonable cheap hotel price main success factor\n",
       "3        bad experience reception give rooms per bookin...\n",
       "4        one best budget friendly hotels hail good swim...\n",
       "                               ...                        \n",
       "19340       crasy price kids games high mantioned price sr\n",
       "19341                  great place much fun friends family\n",
       "19342    good collections games leasure kids cleaniness...\n",
       "19343    غااااااااالي غاااالي اقل شحن حوالي سلامااااااا...\n",
       "19344    maintainanceit closed another one near radison...\n",
       "Name: Cleaned Review, Length: 17762, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1.3: Define a cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # remove numbers\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation\n",
    "    tokens = word_tokenize(text)  # tokenize\n",
    "    stop_words = set(stopwords.words('english'))  # can extend this for Arabic etc.\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # remove stopwords\n",
    "    return ' '.join(tokens)  # join back into string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fdf7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.4: Apply cleaning\n",
    "review['Cleaned Review'] = review['Review Text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b5a3dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'location best good chains outlets available within km distance rooms big amenities served try room service comment checkin checkout smooth cleanliness could improved'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "review['Cleaned Review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e5e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18fd0625",
   "metadata": {},
   "source": [
    "## ✅ Filter to Keep Only English Reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "51e3b45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows after keeping only English reviews: 17355\n",
      "Languages kept:\n",
      "en       15585\n",
      "en-US     1770\n",
      "Name: Reviewer Language, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define allowed English language tags\n",
    "allowed_langs = ['en', 'en-us']\n",
    "\n",
    "# Filter to keep only rows with 'en' or 'en-US' (case-insensitive)\n",
    "review = review[review['Reviewer Language'].str.lower().isin(allowed_langs)]\n",
    "\n",
    "# Reset index\n",
    "review = review.reset_index(drop=True)\n",
    "\n",
    "# Check result\n",
    "print(f\"Remaining rows after keeping only English reviews: {len(review)}\")\n",
    "print(\"Languages kept:\")\n",
    "print(review['Reviewer Language'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e6b157",
   "metadata": {},
   "source": [
    "## ✅ Step 3: Sentiment Analysis (Labeling Reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2377cfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/farajay96/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Cleaned Review  compound  \\\n",
      "13988  favorite coffee shop qatif beautiful place nic...    0.9787   \n",
      "1679   nice ambience good variety indian food service...    0.8481   \n",
      "15169  amazing place multiple activity areas like ska...    0.7430   \n",
      "10263  visited zoo weekend saturday around cleaning w...    0.7847   \n",
      "13361                                               nice    0.4215   \n",
      "\n",
      "      Sentiment Label  \n",
      "13988        positive  \n",
      "1679         positive  \n",
      "15169        positive  \n",
      "10263        positive  \n",
      "13361        positive  \n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# Download the lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize sentiment analyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply sentiment scoring\n",
    "def get_sentiment_scores(text):\n",
    "    return vader.polarity_scores(text)\n",
    "\n",
    "# Create new sentiment columns\n",
    "sentiment_scores = review['Cleaned Review'].apply(get_sentiment_scores).apply(pd.Series)\n",
    "\n",
    "# Merge back to review DataFrame\n",
    "review = pd.concat([review, sentiment_scores], axis=1)\n",
    "\n",
    "# Label sentiment based on compound score\n",
    "def label_sentiment(compound):\n",
    "    if compound >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "review['Sentiment Label'] = review['compound'].apply(label_sentiment)\n",
    "\n",
    "# Preview results\n",
    "print(review[['Cleaned Review', 'compound', 'Sentiment Label']].sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "722bc75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review[\"Sentiment Label\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7176c57",
   "metadata": {},
   "source": [
    "## More Nuanced Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e313e432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 13:13:55.002348: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-23 13:13:55.584802: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-23 13:13:55.759506: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-04-23 13:13:55.759536: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-04-23 13:13:55.891295: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-23 13:13:58.210593: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-23 13:13:58.211133: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-23 13:13:58.211158: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9240422297f645b98525b4bef0add9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5032238c7c54d4291046992cd3ad6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ba0389b8604a579c01674ed6ba7bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/294 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0569236df9423b9a0279050fc5d26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df56313e1d24ac89a33a519411c4ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15545ad881fa462d9649579310bff52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c801f8e5a14c06ad2ac9ee9850b0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farajay96/.pyenv/versions/lewagon/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (572) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 572].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [86], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m emotion_classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      5\u001b[0m                               model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mj-hartmann/emotion-english-distilroberta-base\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      6\u001b[0m                               return_all_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Apply the model to cleaned reviews (use a sample for speed if needed)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m review[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmotion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mreview\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCleaned Review\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43memotion_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Preview result\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(review[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleaned Review\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmotion\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn [86], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m emotion_classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      5\u001b[0m                               model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mj-hartmann/emotion-english-distilroberta-base\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      6\u001b[0m                               return_all_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Apply the model to cleaned reviews (use a sample for speed if needed)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m review[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmotion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m review[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleaned Review\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43memotion_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Preview result\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(review[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleaned Review\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmotion\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:156\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/transformers/pipelines/base.py:1140\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1134\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         )\n\u001b[1;32m   1138\u001b[0m     )\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/transformers/pipelines/base.py:1147\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1146\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1147\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/transformers/pipelines/base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1045\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1046\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:187\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    186\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1198\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1198\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1210\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:810\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    809\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[0;32m--> 810\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (572) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 572].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the emotion classification pipeline\n",
    "emotion_classifier = pipeline(\"text-classification\",\n",
    "                              model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "                              return_all_scores=False)\n",
    "\n",
    "# Apply the model to cleaned reviews (use a sample for speed if needed)\n",
    "review['Emotion'] = review['Cleaned Review'].apply(lambda x: emotion_classifier(x)[0]['label'])\n",
    "\n",
    "# Preview result\n",
    "print(review[['Cleaned Review', 'Emotion']].sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b246ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
